Assignment: Building "Movi" - The Multimodal Transport
Agent
ðŸš€ Project Scenario
Welcome to MoveInSync! We are building a next-generation, supply-first admin console called
MoveInSync Shuttle. Our platform operates on a clear, layered logic:
â— Layer 1 (Static Assets): Transport managers first define the "static" assets.
1. Stops are created (e.g., "Gavipuram", "Peenya").
2. A Path is created as an ordered sequence of Stops
3. A Route is created by assigning a specific time to a Path. This is all managed in
our manageRoute page.
â— Layer 2 (Dynamic Operations): On a daily basis, managers perform "dynamic"
operations on the busDashboard. They Deploy vehicles onto these Routes, which
then generates Trips, and finally, daily Trip-Sheets for drivers and riders.
Your task is to build a working prototype of our new AI assistant, "Movi".
Movi is a "knowledge-aware" AI agent that helps transport managers perform their complex
tasks. It's a true multimodal assistant that understands voice, text, images, and video to
process commands and learn from our product documentation.
Critically, Movi understands this Stop -> Path -> Route -> Trip data flow and the
consequences of changing dynamic operations (e.g., removing a vehicle from a Trip will
affect bookings and break the Trip-Sheet generation).
ðŸ¤– Core Agent Architecture Requirement
The backend for the Movi assistant must be built using langgraph. We are specifically testing
your ability to build a robust, stateful, and multi-step agent that can manage conditional logic
(like checking for consequences), orchestrate multiple tools, and handle complex user
interactions.
ðŸ“‹ Core Objective
Deliver a working web application prototype that includes:
1. A dummy database of our transport operations based on the Stop -> Path -> Route
logic.

2. A basic, functional two-page admin UI (cloned from our screenshots) that displays and
manages data from the database.
3. A multimodal AI assistant ("Movi") integrated into the UI, powered by a langgraph
agent.
Part 1: The Data Layer (Dummy Database)
Your first task is to design and populate a simple database that reflects our precise operational
flow.
â— Technology: You are free to use any database (e.g., PostgreSQL, MySQL, SQLite,
MongoDB).
â— Task:
1. Define a schema that can store the following interconnected data:
â–  Static Assets (for manageRoute page):
â–  Stops (e.g., stop_id, name, latitude, longitude)
â–  Paths (e.g., path_id, path_name,
ordered_list_of_stop_ids)
â–  Routes (This table combines a Path + Time, as seen in the UI):
route_id, path_id, route_display_name (e.g., "Path2 -
19:45"), shift_time, direction, start_point, end_point,
status ('active', 'deactivated')
â–  Dynamic Assets & Operations (for busDashboard page):
â–  Vehicles (e.g., vehicle_id, license_plate, type
(Bus/Cab), capacity)
â–  Drivers (e.g., driver_id, name, phone_number)
â–  DailyTrips (The items in the left panel like 'Bulk - 00:01'):
trip_id, route_id, display_name,
booking_status_percentage, live_status (e.g., '00:01
IN')
â–  Deployments (The link between vehicles and trips):
deployment_id, trip_id, vehicle_id, driver_id
2. Populate your database with realistic dummy data to fill both pages as seen in
the screenshots. Ensure your Routes table data is derived from Paths and
Stops.
Part 2: The Context Layer (Admin Console UI)

You need to build a simple UI for the transport manager similar to the provided screenshots.
Movi must be present and context-aware on both pages.
â— Technology: You are free to use any web framework (e.g., React, Vu
e,
Angular).
Note: You are allowed and encouraged to use AI coding assistants (e.g., GitHub
Copilot, Cursor, etc) for the UI and the DB part. We are evaluating your AI agent
architecture, not your HTML/CSS skills.
â— Task:
1. Page 1: busDashboard
2. Page 2: manageRoute

3. UI-Context-Aware AI: Movi's chat interface must be present on both pages. The
agent's langgraph state should be aware of which page the user is currently on
(e.g., by you passing currentPage: 'busDashboard').
â–  Example: If the user is on the manageRoute page and asks, "Help me
create a new route," Movi should provide guidance relevant to that page.
Part 3: The Intelligence Layer ("Movi" langgraph Agent)
This is the core of the assignment. You will build the Movi AI assistant.
Movi's Required Capabilities (to be orchestrated by langgraph):
1. Voice & Text I/O:
â—‹ Input: The user must be able to interact with Movi using both text and voice
(Speech-to-Text).
â—‹ Output: Movi's responses should be rendered as text in the chat and spoken
aloud (Text-to-Speech).
2. Perform >10 Actions: Movi must be able to understand user intent and perform at least
10 distinct actions (as tools/functions called by your graph) that reflect the new data
model.
â—‹ Examples (You must implement these):
â–  Read (Dynamic): "How many vehicles are not assigned?"
â–  Read (Dynamic): "What's the status of the 'Bulk - 00:01' trip?"
â–  Read (Static): "List all stops for 'Path-2'."
â–  Read (Static): "Show me all routes that use 'Path-1'."
â–  Create (Dynamic): "Assign vehicle 'MH-12-3456' and driver 'Amit' to the
'Path Path - 00:02' trip."
â–  Delete (Dynamic): "Remove the vehicle from 'Bulk - 00:01'."
â–  Create (Static): "Create a new stop called 'Odeon Circle'."
â–  Create (Static): "Create a new path called 'Tech-Loop' using stops
[Gavipuram, Temple, Peenya]."
â—‹ ...you must add at least 2 more actions of similar complexity.
3. ðŸ§  "Tribal Knowledge" (The langgraph "Consequence" Flow): This is the most
critical requirement for your langgraph implementation. Your agent must model our
product logic.
â—‹ Example Scenario:
â–  User: (On the busDashboard) "Movi, remove the vehicle from 'Bulk -
00:01'."
â–  langgraph State: Your graph should move from [agent_entry] to a
[check_consequences] node.

â–  [check_consequences] Node: This node queries the DB and finds
that this trip is 25% booked (or has any bookings) and is scheduled to
run. It updates the agent_state with this critical info.
â–  langgraph Edge: The graph must conditionally route to a
[get_confirmation] node instead of an [execute_action] node.
â–  Movi Response (from [get_confirmation]): "I can remove the
vehicle. However, please be aware the 'Bulk - 00:01' trip is already 25%
booked by employees. Removing the vehicle will cancel these bookings
and a trip-sheet will fail to generate. Do you want to proceed?"
â–  langgraph State: The graph now persists in this state, waiting for the
user's "yes/no" response.
4. True Multimodal Input (Mandatory): Your langgraph agent must orchestrate tools
that process these inputs.
â—‹ Image Input:
â–  Example: The user uploads a screenshot of the busDashboard and
says, "Remove the vehicle from this trip" (the screenshot could have a red
arrow pointing to the "Bulk - 00:01" row). Your agent must use a vision
tool to identify the trip, update its state, and trigger the "Tribal Knowledge"
flow.
ðŸ“¦ Deliverables
1. A Git repository (GitHub, GitLab) containing your full source code.
2. A detailed README.md file that includes:
â—‹ Architecture & langgraph Graph Explanation:
â–  A brief description of your overall architecture (frontend, backend, DB).
â–  Crucially: A detailed explanation of your langgraph design. You must
describe your agent_state, your main nodes, and the
conditional_edges you used to manage the "Tribal Knowledge" and
multimodal flows. A simple diagram is highly recommended.
â—‹ Setup Instructions: Instructions on how to install dependencies and run the
project locally.
3. A short demo video (2-5 minutes) showing your complete, working application. You
must demonstrate:
â—‹ Both UI pages (busDashboard and manageRoute) functionally working.
â—‹ The "Tribal Knowledge" langgraph flow (showing the "consequence" question).
â—‹ The Image Input feature (e.g., uploading a screenshot of the busDashboard).
â—‹ The UI-Context-Awareness (asking for help on the manageRoute page).
Good luck! We are excited to see your langgraph agent in action.

